#!/usr/bin/env bash
source ${SLURM_SIMULATION_TOOLKIT_RC}
datetime_suffix=$(date +%b%d_%H%M%S)

#######################################################################################################################
########################################### HELPER VARIABLES AND FUNCTIONS ############################################
#######################################################################################################################

simulation_executable="simulation.sh"

function showHelp {

echo "NAME
  $me -
     1) Launches many jobs at in parallel
     2) Wraps simulation.sh script

SYNOPSIS
  $me [OPTIONS] [-- OPTIONS_FOR_BASE_SCRIPT]

OPTIONS
  -h, --help
                          Show this description
  --account ACCOUNT
                          ACCOUNT is the slurm account to use for every job (def-yymao or rrg-yymao).
                          Default is rrg-mao on Cedar, def-yymao otherwise.

  --blocking_job_manifest MANIFEST
                          MANIFEST is a file containing a list of IDs of job that must complete before the current jobs
                          are started. MANIFEST must contain exactly (SIMS/PROCS) job IDs separated by newlines.

                          Blocking happens on a one-to-one basis. For example, if (SIMS/PROCS) is N, then the first job
                          launched by $me will wait until the first ID in MANIFEST has completed. The second job
                          launched by $me will wait until the second ID in MANIFEST has completed. And so on until N.

  --job_name JOB_NAME
                          JOB_NAME is the name of the SLURM job. This will be used in the autogenerated regression
                          summary directory name. If MAX is is provided (see --max_job_in_parallel) an index ranging
                          from 0 to (MAX - 1) will be appended to the job name.

                          Default is 'dat' as of writing this, but should be changed on a per-project basis.

  --max_jobs_in_parallel MAX
                          Enforce a maximum of MAX jobs in parallel for the current user ($USER). This is useful for
                          SLURM systems that don't use a fairshare system (eg. in Beta testing phase of a new cluster.)
                          Makes use of the '--dependency=singleton' option of sbatch.

                          Default is no maximum.

  --num_proc_per_gpu PROCS
                          PROCS is the number of processes, aka simulations, to run on the requested compute resource.

                          If for example you are running the command 'train.py --epochs 200' on a GPU resource, and PROC
                          is 3, then 3 instances of 'train.py --epochs 200' will be launched in parallel on the GPU.

                          Default is 2 (process per resource) on Beihang cluster, 1 otherwise.

  --num_simulations SIMS
                          SIMS is the number of is the number of instances of your base scripts to be launched.
                          $me will launch (SIMS/PROCS) jobs in order to run a total of SIMS instances of the base
                          scripts in parallel.

                          SIMS must be divisible by PROCS. See --num_proc_per_gpu for an explanation of PROCS.

                          Default is 12.

  --time TIME
                          TIME is the time allocated for each job. Example format: '1-23:45:56' ie 1 day, 23 hours,
                          45 minutes, 56 seconds. Default is 4 hours.
"
}

# Echo the command run by the user
# useful if scrolling up in the shell or if called by wrapper script
input_command="${me} $@"

echo "RUNNING:"
echo "${input_command}"
echo ""

########################################################################################################################
######################## SET DEFAULT REGRESSION PARAMETERS -- CHANGE THESE OPTIONALLY ##################################
########################################################################################################################
num_simulations=12
max_jobs_in_parallel=''

########################################################################################################################
###################################### ARGUMENT PROCESSING AND CHECKING ################################################
########################################################################################################################
blocking_jobs=()
while [[ $# -ne 0 ]]; do
  case "$1" in
    -h|--help)
      showHelp
      exit 0
    ;;
    --)
      shift 1
      # pass all arguments following '--' to child script
      child_args="$@"
      shift $#
    ;;
    --account)
      account=$2
      shift 2
    ;;
    --blocking_job_manifest)
      blocking_jobs+=(`cat $2`)
      shift 2
    ;;
    --job_name)
      job_name=$2
      shift 2
    ;;
    --max_jobs_in_parallel)
      max_jobs_in_parallel=$2
      shift 2
    ;;
    --num_proc_per_gpu)
      num_proc_per_gpu=$2
      shift 2
    ;;
    --num_simulations)
      num_simulations=$2
      shift 2
    ;;
    --time)
      time=$2
      shift 2
    ;;
    -*)
      echo "Invalid option $1"
      exit 1
    ;;
  esac
done

if (( ${num_simulations} % ${num_proc_per_gpu} )) ; then
  die "$num_simulations not divisible by $num_proc_per_gpu"
fi

num_jobs=$(echo $((num_simulations / num_proc_per_gpu)))


if [[ "${#blocking_jobs[@]}" -gt ${num_jobs} ]]; then
    msg="Number of blocking jobs (${#blocking_jobs[@]}) in the job manifest ($blocking_job_manifest)"
    msg+=" should be equal to the number of jobs (${num_jobs})."
    die "${msg}"
fi

########################################################################################################################
########################## DETERMINE SUMMARY FILE NAMES AND CREATE REGRESSION DIR ######################################
########################################################################################################################

# Create regression name and regression directory name based on job name and current time
regression_name="${job_name}_${datetime_suffix}"
regression_summary_dir=${SLURM_SIMULATION_REGRESS_DIR}/regression_summary/${regression_name}

# Create names of files that will contain summary information about regression
regression_command_file=${regression_summary_dir}/regression_command.txt
regression_logname_file=${regression_summary_dir}/log_manifest.txt
regression_slurm_logname_file=${regression_summary_dir}/slurm_log_manifest.txt
regression_job_numbers_file=${regression_summary_dir}/job_manifest.txt
regression_slurm_commands_file=${regression_summary_dir}/slurm_commands.txt
hash_reference_file=${regression_summary_dir}/hash_reference.txt

# create regression dir if doesn't exist
mkdir -p ${regression_summary_dir}

########################################################################################################################
######################## DETERMINE ARGUMENTS TO BE PASSED DOWN TO SIMULATION SCRIPT (simulation.sh) ####################
########################################################################################################################
job_script_options="--account ${account} --time ${time} --num_proc_per_gpu ${num_proc_per_gpu}"


########################################################################################################################
################################################ LAUNCH THE JOBS #######################################################
########################################################################################################################
for (( i=0; i<$num_jobs; i++ ));
do
{
   job_unique_options=''
   if [[ "${#blocking_jobs[@]}" -gt 0 ]]; then
     job_unique_options+=" --wait_for_job ${blocking_jobs[$i]}"
   fi

   individual_job_name=$job_name
   if [[ -n ${max_jobs_in_parallel} ]]; then
        last_singleton_id=`cat ${regression_summary_dir}/singleton_id.txt`
        singleton_id=$(((last_singleton_id+1) % ${max_jobs_in_parallel}))
        echo ${singleton_id} > ${regression_summary_dir}/singleton_id.txt
        individual_job_name+="_${singleton_id}"
        job_unique_options+=' --singleton'
   fi

   job_unique_options+=" --job_name ${individual_job_name}"
   ${simulation_executable} ${job_script_options} ${job_unique_options} -- ${child_args} > ${regression_slurm_commands_file}_${i}
   slurm_logfile=$(grep -oP '(?<=--output=)[^ ]+' ${regression_slurm_commands_file}_${i})
   echo ${slurm_logfile} > ${regression_slurm_logname_file}_${i}
   job_number=$(grep "Submitted" ${regression_slurm_commands_file}_${i} | grep -oP '\d+$')

   for (( j=0; j<$num_proc_per_gpu; j++ )); do
      slurm_logdirname=$(dirname $slurm_logfile)
      slurm_logbasename=$(basename $slurm_logfile)
      gpu_number=${j}
      log_basename="${slurm_logbasename%.*}_proc_${gpu_number}.log"
      logfile=$slurm_logdirname/${log_basename}
      echo ${logfile} >> ${regression_logname_file}_${i}
   done

   echo ${job_number} > ${regression_job_numbers_file}_${i}
}&
done
wait

cat ${regression_slurm_logname_file}_* > ${regression_slurm_logname_file}
cat ${regression_logname_file}_* > ${regression_logname_file}
cat ${regression_job_numbers_file}_* > ${regression_job_numbers_file}
cat ${regression_slurm_commands_file}_* > ${regression_slurm_commands_file}
rm ${regression_slurm_logname_file}_* ${regression_logname_file}_*
rm ${regression_job_numbers_file}_* ${regression_slurm_commands_file}_*


########################################################################################################################
#################################### PRINT LOCATION OF SUMMARY FILES TO USER ###########################################
########################################################################################################################

echo "${input_command}" > ${regression_command_file}

# Create a shorthand reference, eg beluga@4k35d00r to be used by regression_status.sh script
# Note: may be used in process_result.sh in the future
hash=$(echo -n `readlink -f $regression_logname_file` | sha1sum | grep -oP '^\w{8}')
reference="${local_cluster}@${hash}"

echo "${reference}" > ${hash_reference file}

echo ""

echo "JOB NUMBERS CONTAINED IN:"
readlink -f ${regression_job_numbers_file}
echo ""

echo "SLURM LOGFILE NAMES CONTAINED IN:"
readlink -f ${regression_slurm_logname_file}
echo ""

echo "LOGFILE NAMES CONTAINED IN:"
readlink -f ${regression_logname_file}
echo ""

echo "SLURM COMMANDS CONTAINED IN:"
readlink -f ${regression_slurm_commands_file}
echo ""

echo "REGRESSION COMMAND CONTAINED IN:"
readlink -f ${regression_command_file}
echo ""

echo "HASH REFERENCE FILE:"
echo $hash_reference_file

echo "HASH REFERENCE:"
echo $reference