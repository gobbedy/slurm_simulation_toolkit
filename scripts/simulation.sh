#!/usr/bin/env bash
source ${SLURM_SIMULATION_TOOLKIT_HOME}/config/simulation_toolkit.rc
source ${SLURM_SIMULATION_TOOLKIT_JOB_RC_PATH} # time, nodes, cpus, gpus, memory to request by cluster

############################################################################################################
######################################## HELP DOCUMENTATION ################################################
############################################################################################################
function showHelp {

echo "NAME - DESCRIPTION

  $me -
     1) Creates output (regression) directory
     2) Launches SLURM job
     3) Wraps slurm.sh script

SYNOPSIS

  $me --base_script [OPTIONS] [-- OPTIONS_FOR_BASE_SCRIPT]

OPTIONS

  -h, --help
                          Show this description
  --account ACCOUNT
                          ACCOUNT is the slurm account to use for every job (def-yymao or rrg-yymao).
                          Default is rrg-mao on Cedar, def-yymao otherwise.

  --base_script BASE_SCRIPT
                          BASE_SCRIPT is the is the path to base script that the user wishes to execute on a SLURM
                          compute node.

  --hold
                          Jobs are submitted in held state. Can be used by parent script to impose a launch order
                          before releasing jobs.

  --job_name JOB_NAME
                          JOB_NAME is the name of the SLURM job. This will be used in the autogenerated slurm and
                          simulation logfiles.

                          Default is 'dat' as of writing this, but should be changed on a per-project basis.

  --mail EMAIL
                          Send user e-mail when job ends. Sends e-mail to EMAIL

  --mem MEM
                          MEM is the amount of memory (eg 500m, 7g) to request.

  --nodes NODES
                          NODES is the number of compute nodes to request.

  --num_cpus CPUS
                          CPUS is the number of CPUs to be allocated to the job.

  --num_gpus NUM_GPUS
                          NUM_GPUS is the number of GPUs to be allocated to the job.

  --num_proc_per_gpu PROCS
                          PROCS is the number of processes, aka simulations, to run on the requested compute resource.

                          If for example you are running the command 'train.py --epochs 200' on a GPU resource, and PROC
                          is 3, then 3 instances of 'train.py --epochs 200' will be launched in parallel on the GPU.

                          Default is 1.

  --regress_dir REGRESS_DIR
                          REGRESS_DIR is the directory beneath which the simulation output directory will be generated.

                          Default is ${SLURM_SIMULATION_TOOLKIT_REGRESS_DIR}.

  --seed SEED
                          SEED is simulation seed. If not provided, base script randomizes.

  --singleton
                          If provided, only one job named JOB_NAME will run at a time by this user on this cluster. If
                          a job named JOB_NAME is already running, this job will wait for that job to finish before
                          starting. Similarly, if this job is running, any future job named JOB_NAME and having used
                          the --singleton switch will wait for this job to finish.

                          Disabled by default.
  --time TIME
                          TIME is the time allocated for the job. Example format: '1-23:45:56' ie 1 day, 23 hours,
                          45 minutes, 56 seconds. Default is 4 hours.

  --wait_for_job JOB_ID
                          If provided, the current job will wait for job with ID JOB_ID before starting.

"
}

########################################################################################################################
######################################## SET DEFAULT REGRESSION PARAMETERS #############################################
########################################################################################################################
seed=''
blocking_job_id=''
singleton='no'
regress_dir=${SLURM_SIMULATION_TOOLKIT_REGRESS_DIR}
base_script=''
hold=''

########################################################################################################################
###################################### ARGUMENT PROCESSING AND CHECKING ################################################
########################################################################################################################
while [[ $# -ne 0 ]]; do
  case "$1" in
    -h|--help)
      showHelp
      exit 0
    ;;
    --)
      shift 1
      # pass all arguments following '--' to child script
      child_args="$@"
      shift $#
      break
    ;;
    --account)
      account=$2
      shift 2
    ;;
    --base_script)
      base_script=$2
      shift 2
    ;;
    --hold)
      hold=yes
      shift 1
    ;;
    --num_cpus)
      cpus=$2
      shift 2
    ;;
    --num_gpus)
      gpus=$2
      shift 2
    ;;
    --job_name)
      job_name=$2
      shift 2
    ;;
    --mail)
      email=yes
      EMAIL=$2
      shift 2
      if [[ ${EMAIL} == -* ]]; then
          echo "ERROR: invalid email: ${EMAIL}"
          exit 1
      fi
      if [[ ${EMAIL} != *@* ]]; then
          echo "ERROR: invalid email: ${EMAIL}"
          exit 1
      fi
    ;;
    --mem)
      mem=$2
      shift 2
    ;;
    --nodes)
      nodes=$2
      shift 2
    ;;
    --num_proc_per_gpu)
      num_proc_per_gpu=$2
      shift 2
    ;;
    --regress_dir)
      regress_dir=$2
      shift 2
    ;;
    -s|--seed)
      seed=$2
      shift 2
    ;;
    --singleton)
      singleton='yes'
      shift 1
    ;;
    --time)
      time=$2
      shift 2
    ;;
    --wait_for_job)
      blocking_job_id=$2
      shift 2
    ;;
    -*)
      die "Invalid option $1"
    ;;
  esac
done

if [[ -z ${base_script} ]]; then
    die "Base script must be provided via --base_script option."
fi

if [[ ! -f ${base_script} ]]; then
    die "Invalid base script: ${base_script}"
fi
base_script=$(readlink -f ${base_script})

############################################################################################################
######################################### SIMULATION PARAMETERS ############################################
############################################################################################################

# directory where simulation output will reside -- to be autogenerated
output_dir=${regress_dir}/$(openssl rand -hex 4)

############################################################################################################
################################### PREPARE THE JOB LAUNCH #################################################
############################################################################################################

# slurm logile where simulation output will reside
slurm_logfile=${output_dir}/${job_name}.slurm

###### create regression output directory tree #####
mkdir -p ${output_dir}

# Copy current working directory to output_dir.
# This serves as a snapshotting of current code for later debugging (useful when running simultaneous sims)
source_code_dir=$(dirname ${base_script})
cp -rp ${source_code_dir}/* ${output_dir}
base_script_copy="${output_dir}/$(basename ${base_script})"

# full path to copied sbatch script
sbatch_script_path="${SLURM_SIMULATION_TOOLKIT_SBATCH_SCRIPT_PATH}"

# prepare arguments to job script (slurm.sh)
export="script_path=\"${base_script_copy}\",output_dir=\"${output_dir}\",ALL"

simulation_options="-t ${time} -j ${job_name} --output ${slurm_logfile} -n ${nodes} -c ${cpus} -g ${gpus} -m ${mem}"
simulation_options+=" --num_proc_per_gpu ${num_proc_per_gpu} --cmd sbatch --account ${account}"
if [[ ${email} == yes ]]; then
  simulation_options+=" --mail $EMAIL"
fi

if [[ ${hold} == "yes" ]]; then
  simulation_options+=" --hold"
fi

if [[ ${test_mode} == yes ]]; then
  simulation_options+=" --test"
fi

if [[ -n ${blocking_job_id} ]]; then
  simulation_options+=" --wait_for_job ${blocking_job_id}"
fi

if [[ ${singleton} == 'yes' ]]; then
  simulation_options+=" --singleton"
fi

simulation_options+=" --script_name ${sbatch_script_path}"

echo "${me}: SLURM LOGFILE:"
echo  ${slurm_logfile}
echo ""

############################################################################################################
################################ LAUNCH THE JOB (ie call slurm.sh) #########################################
############################################################################################################

# launch job (more exactly, call job launching script slurm.sh)
slurm.sh ${simulation_options} -e "${export}" -- ${child_args} |& tee -a ${slurm_logfile}

# same slurm_logfile will be used to output job content -- add a header to separate this script's output from slurm.sh output
echo "" >> ${slurm_logfile}
echo "${me}: JOB OUTPUT:" >> ${slurm_logfile}